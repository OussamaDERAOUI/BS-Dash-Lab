{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRLRjKqcUckO",
    "outputId": "81d42c9c-4ba6-4fe2-dacb-9fae6092c0c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\usuario\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\usuario\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f1f7a4d4-76ab-41e5-8eed-1a26ce83d9ba",
     "showTitle": false,
     "title": ""
    },
    "id": "tWGNE35wUO8j"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# This is the regular expression specific to Apache log analysis, which can be changed to different log formats as needed\n",
    "# Example of an Apache log line:\n",
    "#                              127.0.0.1 - - [21/Jul/2014:9:55:27 -0800] \"GET /home.html HTTP/1.1\" 200 2048\n",
    "#                              1:IP  2:client 3:user 4:date time           5:method 6:req 7:proto   8:respcode 9:size\n",
    "APACHE_ACCESS_LOG_PATTERN = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (\\S+) (\\S+)\" (\\d{3}) (\\d+)'\n",
    "\n",
    "# The function below is modeled specifically to the Apache Access Logs model, which can be modified as needed for different log formats\n",
    "# Return a dictionary containing the Apache access log parts.\n",
    "def parse_apache_log_line(logline):\n",
    "    match = re.search(APACHE_ACCESS_LOG_PATTERN, logline)\n",
    "    if match is None:\n",
    "        raise Error(\"Invalid logline: %s\" % logline)\n",
    "    return Row(\n",
    "        ip_address    = match.group(1),\n",
    "        client_identd = match.group(2),\n",
    "        user_id       = match.group(3),\n",
    "        date = (match.group(4)[:-6]).split(\":\", 1)[0],\n",
    "        time = (match.group(4)[:-6]).split(\":\", 1)[1],\n",
    "        method        = match.group(5),\n",
    "        endpoint      = match.group(6),\n",
    "        protocol      = match.group(7),\n",
    "        response_code = int(match.group(8)),\n",
    "        content_size  = int(match.group(9))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oD0gu_k9VnfN",
    "outputId": "e1ef6d99-1200-4892-cac7-8c70a34fe814"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m logFile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./apache.access.log\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# .cache() - Keeps the RDD in memory, which will be reused\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m access_logs \u001b[38;5;241m=\u001b[39m (\u001b[43msc\u001b[49m\u001b[38;5;241m.\u001b[39mtextFile(logFile)\n\u001b[0;32m     11\u001b[0m                \u001b[38;5;241m.\u001b[39mmap(parse_apache_log_line)\n\u001b[0;32m     12\u001b[0m                \u001b[38;5;241m.\u001b[39mcache())\n\u001b[0;32m     13\u001b[0m access_logs\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "import sys\n",
    "\n",
    "\n",
    "#input file\n",
    "logFile = './apache.access.log'\n",
    "\n",
    "# .cache() - Keeps the RDD in memory, which will be reused\n",
    "access_logs = (sc.textFile(logFile)\n",
    "               .map(parse_apache_log_line)\n",
    "               .cache())\n",
    "access_logs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6dfcf02f-a803-4fb1-8cfc-c0a2472c5925",
     "showTitle": false,
     "title": ""
    },
    "id": "zZ3N5QpQUO8m"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"ApacheLogAnalysis\").getOrCreate()\n",
    "\n",
    "# .cache() - Keeps the RDD in memory, which will be reused\n",
    "access_logs = (sc.textFile(logFile)\n",
    "               .map(parse_apache_log_line)\n",
    "               .cache())\n",
    "\n",
    "# Create a DataFrame from the RDD\n",
    "schema_access_logs = spark.createDataFrame(access_logs)\n",
    "\n",
    "# Create a table on which SQL-type queries can be triggered for analysis\n",
    "schema_access_logs.createOrReplaceTempView(\"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "eac54e92-bb1e-4737-b3b4-2eb531dc4882",
     "showTitle": false,
     "title": ""
    },
    "id": "R57v5r0uUO8n"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Traffic size per address (page or endpoint)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m topEndpointsMaxSize \u001b[38;5;241m=\u001b[39m (\u001b[43mspark\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT endpoint, content_size/1024 FROM logs ORDER BY content_size DESC LIMIT 10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: (row[\u001b[38;5;241m0\u001b[39m], row[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mcollect())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Traffic size per address (page or endpoint)\n",
    "topEndpointsMaxSize = (spark\n",
    "    .sql(\"SELECT endpoint, content_size/1024 FROM logs ORDER BY content_size DESC LIMIT 10\")\n",
    "    .rdd.map(lambda row: (row[0], row[1]))\n",
    "    .collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5edef2a7-7e2b-4d43-8ac1-74b326c3a7e5",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "PABgZ4NqUO8n",
    "outputId": "b8bc448d-90d9-42e0-dd61-18da866f349c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topEndpointsMaxSize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(\u001b[43mtopEndpointsMaxSize\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'topEndpointsMaxSize' is not defined"
     ]
    }
   ],
   "source": [
    "display(topEndpointsMaxSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "907a7c09-8931-48e5-873b-1144e30c12de",
     "showTitle": false,
     "title": ""
    },
    "id": "NzSW3_JYUO8n"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Display the number of times a response code has been triggered\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m responseCodeToCount \u001b[38;5;241m=\u001b[39m (\u001b[43mspark\u001b[49m\n\u001b[0;32m      3\u001b[0m                        \u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT response_code, COUNT(*) AS theCount FROM logs GROUP BY response_code\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m                        \u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: (row[\u001b[38;5;241m0\u001b[39m], row[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      5\u001b[0m                        \u001b[38;5;241m.\u001b[39mcollect())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Display the number of times a response code has been triggered\n",
    "responseCodeToCount = (spark\n",
    "                       .sql(\"SELECT response_code, COUNT(*) AS theCount FROM logs GROUP BY response_code\")\n",
    "                       .rdd.map(lambda row: (row[0], row[1]))\n",
    "                       .collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3e15d6b4-6eac-4edc-8373-b182edd0e05a",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "GQXLs2vsUO8n",
    "outputId": "bf89833e-8cde-44cc-9161-6a38b26fa5cf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'responseCodeToCount' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(\u001b[43mresponseCodeToCount\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'responseCodeToCount' is not defined"
     ]
    }
   ],
   "source": [
    "display(responseCodeToCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0e749e01-7e72-45f9-bdff-979a38364ed3",
     "showTitle": false,
     "title": ""
    },
    "id": "DeezMKbbUO8o"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# the number of occurrences of each IP address that has browsed the site (only addresses with a total greater than 10 will be displayed)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m frequentIpAddressesHits \u001b[38;5;241m=\u001b[39m (\u001b[43mspark\u001b[49m\n\u001b[0;32m      3\u001b[0m                            \u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT ip_address, COUNT(*) AS total FROM logs GROUP BY ip_address HAVING total > 10\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m                            \u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: (row[\u001b[38;5;241m0\u001b[39m], row[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m      5\u001b[0m                            \u001b[38;5;241m.\u001b[39mcollect())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# the number of occurrences of each IP address that has browsed the site (only addresses with a total greater than 10 will be displayed)\n",
    "frequentIpAddressesHits = (spark\n",
    "                           .sql(\"SELECT ip_address, COUNT(*) AS total FROM logs GROUP BY ip_address HAVING total > 10\")\n",
    "                           .rdd.map(lambda row: (row[0], row[1]))\n",
    "                           .collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "37d3f3ed-85de-48c3-a90d-2ae2560ea962",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8PcI2aUUO8o",
    "outputId": "4426fcb0-94d9-4df3-c3b8-c9087f432a87"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frequentIpAddressesHits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfrequentIpAddressesHits\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frequentIpAddressesHits' is not defined"
     ]
    }
   ],
   "source": [
    "frequentIpAddressesHits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "44312c25-4a52-4778-a9e0-7888b7750e53",
     "showTitle": false,
     "title": ""
    },
    "id": "tCNVgL1OUO8o"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m frequentIpAddressesHits \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mcreateDataFrame(frequentIpAddressesHits)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "frequentIpAddressesHits = spark.createDataFrame(frequentIpAddressesHits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fc1479a0-59c3-45be-8e39-83050f07698d",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "iSQ_Jb8nUO8o",
    "outputId": "e4bcd260-e898-4520-a898-68484623cf72"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frequentIpAddressesHits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(\u001b[43mfrequentIpAddressesHits\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frequentIpAddressesHits' is not defined"
     ]
    }
   ],
   "source": [
    "display(frequentIpAddressesHits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "74203ab5-8ca0-43fd-9b40-2895e60d1c10",
     "showTitle": false,
     "title": ""
    },
    "id": "4gvTNbHSUO8p"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# traffic size by date\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m trafficWithTime \u001b[38;5;241m=\u001b[39m (\u001b[43mspark\u001b[49m\n\u001b[0;32m      3\u001b[0m                    \u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT date, content_size/1024 FROM logs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m                    \u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: (row[\u001b[38;5;241m0\u001b[39m], row[\u001b[38;5;241m1\u001b[39m])))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# traffic size by date\n",
    "trafficWithTime = (spark\n",
    "                   .sql(\"SELECT date, content_size/1024 FROM logs\")\n",
    "                   .rdd.map(lambda row: (row[0], row[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "865e96fa-e5cf-4712-86bb-47a89f03b2a5",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ORYr47TUO8p",
    "outputId": "283cf442-8739-4ddf-9875-b819e7130272"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trafficWithTime \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mcreateDataFrame(trafficWithTime)\n\u001b[0;32m      2\u001b[0m trafficWithTime\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "trafficWithTime = spark.createDataFrame(trafficWithTime)\n",
    "trafficWithTime.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "261e9efa-d76e-44ad-a981-8a7e0565937f",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "uIfAqfucUO8p",
    "outputId": "10320c5c-1d87-4076-b415-917cd6bb1005"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trafficWithTime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(\u001b[43mtrafficWithTime\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trafficWithTime' is not defined"
     ]
    }
   ],
   "source": [
    "display(trafficWithTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7a68be00-159f-41a1-9c0d-a59b6395cf32",
     "showTitle": false,
     "title": ""
    },
    "id": "E5CvWiGAUO8p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "LogAnalysis",
   "notebookOrigID": 4098204479520561,
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
